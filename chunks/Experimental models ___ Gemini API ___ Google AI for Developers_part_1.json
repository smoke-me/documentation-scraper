{
  "text": "# Experimental models ___ Gemini API ___ Google AI for Developers In addition to the production ready models, the Gemini API offers experimental models available in Preview, as defined in the Terms, meaning the models are not for production use. We release experimental models to gather feedback, get our latest updates into the hands of developers quickly, and highlight the pace of innovation happening at Google. What we learn from experimental launches informs how we release models more widely. An experimental model can be swapped for another without prior notice. We don't guarantee that an experimental model will become a stable model in the future. The Gemini API's experimental models are available for all users. You can use the experimental models either in your code directly using the Gemini API, or you can use an experimental model in Google AI Studio: To use an experimental model, specify the model code. For example: response = client.models.generate_content( model=\"gemini-2.0-flash-exp\", contents=\"How does RLHF work?\" ) response = client.models.generate_content( model=\"gemini-2.0-flash-exp\", contents=\"How does RLHF work?\" ) Select the model code of the experimental model you want to use in the Model drop-down menu in the Settings pane. Experimental models are labeled Preview in the drop-down menu. You can view the rate limits for each model on the rate limits page. Gemini 2.0 Flash Experimental provides several new capabilities in private preview release. Gemini 2.0 supports a new multimodal generation capability: text to speech. Using the text-to-speech capability, you can prompt the model to generate high quality audio output that sounds like a human voice (say \"hi everyone\"), and you can further refine the output by steering the voice. Gemini 2.0 supports the ability to output text with inline images. This lets you use Gemini to conversationally edit images or generate multimodal outputs (for example, a blog post with text and images in a single turn). Previously this would have required stringing together multiple models. Image generation is available as a private experimental release. It supports the following modalities and capabilities: Text to image Example prompt: \"Generate an image of the Eiffel tower with fireworks in the background.\" Example prompt: \"Generate an image of the Eiffel tower with fireworks in the background.\" Text to image(s) and text (interleaved) Example prompt: \"Generate an illustrated recipe for a paella.\" Example prompt: \"Generate an illustrated recipe for a paella.\" Image(s) and text to image(s) and text (interleaved) Example prompt: (With an image of a furnished room) \"What other color sofas would work in my space? can you update the image?\" Example prompt: (With an image of a furnished room) \"What other color sofas would work in my space? can you update the image?\" Image editing (text and image to image) Example prompt: \"Edit this image to make it look like a cartoon\" Example prompt: [image of a cat] + [image of a pillow] + \"Create a cross stitch of my cat on this pillow.\" Example prompt: \"Edit this image to make it look like a cartoon\" Example prompt: [image of a cat] + [image of a pillow] + \"Create a cross stitch of my cat on this pillow.\" Multi-turn image editing (chat) Example prompts: [upload an image of a blue car.] \"Turn this car into a convertible.\" \"Now change the color to yellow.\" Example prompts: [upload an image of a blue car.] \"Turn this car into a convertible.\" \"Now change the color to yellow.\" Watermarking All generated images include a SynthID watermark. Generation of people and editing of uploaded images of people are not allowed. For best performance, use the following languages: EN, es-MX, ja-JP, zh-CN, hi-IN. Image generation does not support audio or video inputs. Image generation may not always trigger: The model may output text only. Try asking for image outputs explicitly (e.g. \"generate an image\", \"provide images as you go along\", \"update the image\"). The model may stop generating partway through. Try again or try a different prompt. The model may output text only. Try asking for image outputs explicitly (e.g. \"generate an image\", \"provide images as you go along\", \"update the image\"). The model may stop generating partway through. Try again or try a different prompt. You can provide feedback on the Gemini API's experimental models using our developer forum. As new versions or stable releases become available, we remove and replace experimental models. You can find the previous experimental models we released in the following section along with the replacement version: Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.",
  "source": "Experimental models ___ Gemini API ___ Google AI for Developers.txt",
  "token_count": 1060
}