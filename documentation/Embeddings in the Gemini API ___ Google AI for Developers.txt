URL: https://ai.google.dev/gemini-api/docs/embeddings
Token Count: 1105

The text-embedding-004 model generates state-of-the-art embeddings for words, phrases, and sentences. The resulting embeddings can then be used for tasks such as semantic search, text classification, and clustering, among many others. For more information on embeddings, read our research paper. Embeddings capture semantic meaning and context, which results in text with similar meanings having "closer" embeddings. For example, the sentence "I took my dog to the vet" and "I took my cat to the vet" would have embeddings that are close to each other in the vector space since they both describe a similar context. You can use embeddings to compare different texts and understand how they relate. For example, if the embeddings of the text "cat" and "dog" are close together you can infer that these words are similar in meaning, context, or both. This enables a variety of common AI use cases. Use the embedContent method to generate text embeddings: from google import genai from google.genai import types client = genai.Client(api_key="GEMINI_API_KEY") result = client.models.embed_content( model="text-embedding-004", contents="What is the meaning of life?") print(result.embeddings) from google import genai from google.genai import types client = genai.Client(api_key="GEMINI_API_KEY") result = client.models.embed_content( model="text-embedding-004", contents="What is the meaning of life?") print(result.embeddings) const { GoogleGenerativeAI } = require("@google/generative-ai"); const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY); const model = genAI.getGenerativeModel({ model: "text-embedding-004"}); async function run() { const result = await model.embedContent("What is the meaning of life?"); console.log(result.embedding.values); } run(); const { GoogleGenerativeAI } = require("@google/generative-ai"); const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY); const model = genAI.getGenerativeModel({ model: "text-embedding-004"}); async function run() { const result = await model.embedContent("What is the meaning of life?"); console.log(result.embedding.values); } run(); curl "https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent?key=$GEMINI_API_KEY" \ -H 'Content-Type: application/json' \ -d '{"model": "models/text-embedding-004", "content": { "parts":[{ "text": "What is the meaning of life?"}]} }' curl "https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent?key=$GEMINI_API_KEY" \ -H 'Content-Type: application/json' \ -d '{"model": "models/text-embedding-004", "content": { "parts":[{ "text": "What is the meaning of life?"}]} }' ctx := context.Background() client, err := genai.NewClient(ctx, option.WithAPIKey(os.Getenv("GEMINI_API_KEY"))) if err != nil { log.Fatal(err) } defer client.Close() em := client.EmbeddingModel("text-embedding-004") res, err := em.EmbedContent(ctx, genai.Text("What is the meaning of life?")) if err != nil { panic(err) } fmt.Println(res.Embedding.Values) ctx := context.Background() client, err := genai.NewClient(ctx, option.WithAPIKey(os.Getenv("GEMINI_API_KEY"))) if err != nil { log.Fatal(err) } defer client.Close() em := client.EmbeddingModel("text-embedding-004") res, err := em.EmbedContent(ctx, genai.Text("What is the meaning of life?")) if err != nil { panic(err) } fmt.Println(res.Embedding.Values) Text embeddings are used in a variety of common AI use cases, such as: Information retrieval: You can use embeddings to retrieve semantically similar text given a piece of input text. Document search tutorialtask Information retrieval: You can use embeddings to retrieve semantically similar text given a piece of input text. Clustering: Comparing groups of embeddings can help identify hidden trends. Embedding clustering tutorialbubble_chart Clustering: Comparing groups of embeddings can help identify hidden trends. Vector database: As you take different embedding use cases to production, it is common to store embeddings in a vector database. Vector database tutorialbolt Vector database: As you take different embedding use cases to production, it is common to store embeddings in a vector database. Classification: You can train a model using embeddings to classify documents into categories. Classification tutorialtoken Classification: You can train a model using embeddings to classify documents into categories. The Gemini API offers two models that generate text embeddings: Text Embeddings is an updated version of the Embedding model that offers elastic embedding sizes under 768 dimensions. Elastic embeddings generate smaller output dimensions and potentially save computing and storage costs with minor performance loss. Use Text Embeddings for new projects or applications. Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.